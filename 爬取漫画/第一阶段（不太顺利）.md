https://www.dmzj.com/info/yaoshenji.html 
这是动漫之家的妖神记的章节网页
![image](https://github.com/yexiaoyaoo/python_spider/assets/125390278/14bc8598-11cc-42ca-8043-38474ba2fd3d)
可以看到有章节信息，正当我欣喜若狂想要先把所有章节名称爬出来，再点击章节链接保存图片，并且坚信每个章节的url跟电子书一样非常有规律
我先f12，查看元素
![image](https://github.com/yexiaoyaoo/python_spider/assets/125390278/d8faf1f4-08d4-4e66-8b07-aa846476803d)
稳啦，就电子书套路很像，老三样 requests BeautifulSoup 再text打印出来悄悄，但是 得到的却是none ，于是问了问gpt，原来是动态加载的原因，一下变得棘手了

我是通过使用Chrome DevTools来检查网页的网络请求和响应的。具体的步骤是：

- 打开Chrome浏览器，访问https://www.dmzj.com/info/yaoshenji.html这个网页。
- 按F12键或者右键点击页面，选择检查（Inspect）选项，打开Chrome DevTools。
- 点击Network标签，查看网页的网络活动。
- 刷新网页，观察Network标签下的请求和响应。
- 在Filter栏输入list_con_zj，过滤出包含这个关键词的请求和响应。
- 可以看到有一个请求的Name是https://v3api.dmzj.com/comic/comic_4722.json?channel=Android&version=2.7.019，它的Type是xhr，表示是一个Ajax请求。
- 点击这个请求，查看它的详细信息。可以看到它的Response标签下有一段JSON格式的数据，其中包含了漫画的所有章节的信息，如标题、链接、更新时间等。
- 这说明这个网页是通过JavaScript动态加载了这段JSON数据，并且用它来生成<span class="list_con_zj">元素和它的子元素<a>。所以你用requests.get方法获取的网页源代码里没有这个元素，因为它是在浏览器里执行了JavaScript后才生成的。

-
- 于是我点击网络，查看一番，果然发现了猫腻
- ![image](https://github.com/yexiaoyaoo/python_spider/assets/125390278/c7d88bd6-b187-43ae-b947-d6e80f240f8c)
- 我利用python看看能不能得到这些网址，以为每个章节应该有规律
- ![image](https://github.com/yexiaoyaoo/python_spider/assets/125390278/d80ad24f-f5ff-4019-9fde-9b453af49737)
- 但是发现每个章节的规律虽然是后三位数变化但并不是但累加方式的，不是很会，先学学selenium吧
- selenium 是一个用于浏览器自动化的工具，它可以让 Python 控制浏览器，模拟用户的操作，从而实现网页数据的抓取。selenium 的优点是可以处理动态加载的内容，可以执行 JavaScript 代码，可以模拟各种事件，如点击、滚动、悬停等。selenium 的缺点是需要安装浏览器驱动，速度比较慢，占用资源较多。

selenium 爬虫是否是最好的，这要根据具体的需求和场景来判断。如果你需要抓取的网站是静态的，没有反爬措施，那么你可以使用更简单和快速的 requests + BeautifulSoup 组合。如果你需要抓取的网站是动态的，有反爬措施，或者你需要模拟复杂的用户行为，那么你可以使用 selenium 来实现。

如果你想了解更多关于 selenium 网页抓取的信息，你可以参考以下的链接：

¹ [Web Scraping using Selenium and Python | ScrapingBee](https://www.scrapingbee.com/blog/selenium-python/)
² [Web Scraping with Selenium | Pluralsight](https://www.pluralsight.com/guides/web-scraping-with-selenium)
³ [Cómo hacer Web Scraping con Selenium | OpenWebinars](https://openwebinars.net/blog/como-hacer-web-scraping-con-selenium/)
⁴ [Web Scraping with Selenium with examples & code | Nanonets](https://nanonets.com/blog/web-scraping-with-selenium/)

源: 与必应的对话， 2023/7/29
(1) Web Scraping using Selenium and Python | ScrapingBee. https://www.scrapingbee.com/blog/selenium-python/.
(2) Web Scraping with Selenium | Pluralsight. https://www.pluralsight.com/guides/web-scraping-with-selenium.
(3) Cómo hacer Web Scraping con Selenium | OpenWebinars. https://openwebinars.net/blog/como-hacer-web-scraping-con-selenium/.
(4) Web Scraping with Selenium with examples & code | Nanonets. https://nanonets.com/blog/web-scraping-with-selenium/.


